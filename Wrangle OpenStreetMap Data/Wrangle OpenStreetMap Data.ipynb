{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle OpenStreetMap Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this map data wrangling project, I selected my home state of Rhode Island. It is about the size of some larger urban areas, so I figured it might pose an interesting choice! The map data I downloaded from [Geofabrik](http://download.geofabrik.de/north-america/us/rhode-island.html), which already has a pre made Rhode Island openstreetmap data file. The area extends into the ocean to include Block Island, an offshore town in the state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Investigation and Auditing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several issues were identified in the data:\n",
    "* Inconsistent and abbreviated street names (Point Judith Rd, Cunningham Sq)\n",
    "* Incorrect or inconsistent zip codes (02835, 02903-2996, 029212)\n",
    "* Street names embedded in Tiger GPS blocks in ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Street Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, like the case study, I looked into street abbreviations and found that there were many nodes with inconsistencies. Fixing these abbreviations will help standardize the data and make for easier analysis of addresses if needed.  The update_street_name code was used in the conversion to csv to fix the street names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "def update_street_name(name, mapping):\n",
    "    \"\"\"\n",
    "    Takes in an abnormal street name and returns a corrected one\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the street type and correct if possible\n",
    "    street_type = re.search(street_type_re, name).group()\n",
    "    if street_type in mapping:\n",
    "        name = name.replace(street_type, mapping[street_type], 1)\n",
    "\n",
    "    return name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code would take something like Point Judith Rd and replace it with Point Judith Road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Postcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important facet of the address is the post code - auditing this is not particularly difficult and can easily find some mistakes. Upon searching through the postal codes in the OSM database, it was clear that most had the standard five digit form. However, some included the final four digits after the hyphen and a few were the wrong length entirely, probably due to human input.\n",
    "\n",
    "The function update_postcodes is used during csv conversion to check for inconsistent postal codes. It will omit records that are likely a result of typos, and only return the first five digits of a postcode found with the hyphen format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def update_postcodes(code):\n",
    "    \"\"\"\n",
    "    Takes a postcode and updates it to a valid 5 digit postcode\n",
    "    \"\"\"\n",
    "    # If the postcode is the proper length, return it\n",
    "    if len(code) == 5:\n",
    "        return code\n",
    "    # Otherwise, if the postcode has a dash only return the first five digits\n",
    "    elif '-' in code:\n",
    "        return code[:5]\n",
    "    # If the postcode does not fall in to these catigories, return None\n",
    "    else:\n",
    "        return None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the update_postcodes function would make the following changes:\n",
    "\n",
    "```\n",
    "02835      => 02835\n",
    "02903-2996 => 02903\n",
    "029212     => None, omit record\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Tiger GPS Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While doing a quick through the data, I noticed that there were a lot of ways with their names broken up into segments in a different format. They always had the key start with 'tiger:' which I assumed to mean that they came from an automated upload. Tiger GPS blocks typically have the following format:\n",
    "\n",
    "```xml\n",
    "<tag k=\"name\" v=\"Commonwealth Avenue\" />\n",
    "<tag k=\"highway\" v=\"residential\" />\n",
    "<tag k=\"tiger:cfcc\" v=\"A41\" />\n",
    "<tag k=\"tiger:county\" v=\"Bristol, RI\" />\n",
    "<tag k=\"tiger:reviewed\" v=\"no\" />\n",
    "<tag k=\"tiger:zip_left\" v=\"02806\" />\n",
    "<tag k=\"tiger:name_base\" v=\"Commonwealth\" />\n",
    "<tag k=\"tiger:name_type\" v=\"Ave\" />\n",
    "<tag k=\"tiger:zip_right\" v=\"02806\" />\n",
    "```\n",
    "\n",
    "You can see that this block has already been collated with a name at the top fo the block in the normal format. During the audit, I decided to check if there were any tiger GPS blocks that had not yet been updated with a name tag. It turns out there were several, and adding the name tag would be useful for standardizing the database. The update_tiger function is used during csv conversion to return the name element. The function also calls the earlier function, update_street_name, to check for abbreviated road types and replace them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def update_tiger(parent_id, tiger_name, tiger_type):\n",
    "    \"\"\"\n",
    "    Function takes in a parent id, tiger name, and tiger type and returns\n",
    "    a dictionary with the appropriate name dictionary. Should only be called\n",
    "    when the tiger name has not yet been compiled.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize a child dict with the appropriate type, key, and id\n",
    "    child_dict = {'id':parent_id,\n",
    "                  'type':'regular',\n",
    "                  'key':'name'}\n",
    "\n",
    "    # combine the tiger parts into a full street name\n",
    "    street = tiger_name + ' ' + tiger_type\n",
    "\n",
    "    # use the street audit function to fix any abbreviation issues\n",
    "    street_final = audit_streetnames.update_street_name(street,\n",
    "                                                    audit_streetnames.mapping)\n",
    "\n",
    "    # print 'Updated', tiger_name, tiger_type,' => ', street_final\n",
    "    child_dict['value'] = street_final\n",
    "    return child_dict\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, this function would take in the following block and add a name element.\n",
    "```xml\n",
    "<tag k=\"tiger:name_base\" v=\"Commonwealth\" />\n",
    "<tag k=\"tiger:name_type\" v=\"Ave\" />\n",
    "```\n",
    "This would add the name element:\n",
    "```xml\n",
    "<tag k=\"name\" v=\"Commonwealth Avenue\" />\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Analysis and Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by listing the file sizes for some important files:\n",
    "```\n",
    "rhode-island-latest.osm   185 MB\n",
    "ri_osm.db                 98.9 MB\n",
    "nodes.csv                 71.2 MB\n",
    "nodes_tags.csv            2.5 MB\n",
    "ways.csv                  5.3 MB\n",
    "ways_tags.csv             12.1 MB\n",
    "ways_nodes.csv            22.8 MB\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next we query to total number of nodes:\n",
    "```SQL\n",
    "SELECT count(*) FROM nodes;\n",
    "```\n",
    "846158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The total number of ways:\n",
    "```SQL\n",
    "SELECT count(*) FROM ways;\n",
    "```\n",
    "\n",
    "89540"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The number of distinct users, combining both the nodes and ways database:\n",
    "```SQL\n",
    "SELECT COUNT(DISTINCT(combined.uid)) FROM\n",
    "(SELECT uid FROM nodes\n",
    "UNION ALL\n",
    "SELECT uid FROM ways) combined;\n",
    "```\n",
    "803"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of shops in the database:\n",
    "```SQL\n",
    "SELECT COUNT(*) \n",
    "  FROM (SELECT key FROM nodes_tags\n",
    "  UNION ALL\n",
    "  SELECT key FROM ways_tags) combined\n",
    "  WHERE key = \"shop\";\n",
    "```\n",
    "412"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will compute some additional statistics to explore the database. First, we can look at the most common keys in node_tags to see what is available for exploration.\n",
    "```SQL\n",
    "SELECT key, count(*) as num\n",
    "FROM nodes_tags\n",
    "GROUP BY key\n",
    "ORDER BY num DESC;\n",
    "```\n",
    "```\n",
    "source      7119\n",
    "attribution 6462\n",
    "name        4647\n",
    "power       4466\n",
    "ele         3441\n",
    "feature_id  3116\n",
    "amenity     2771\n",
    "created     2564\n",
    "county_id   2373\n",
    "state_id    2373\n",
    "highway     1947\n",
    "natural     1752\n",
    "```\n",
    "\n",
    "The most noticable thing is that so many of the keys are for source and other internal documentation use. Of the remaining common keys, amenity and natural seem to be the most interesting to explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start exploring amenities, we will look at the ten most common amenities:\n",
    "```SQL\n",
    "SELECT nodes_tags.value, COUNT(*) as num\n",
    "  FROM nodes_tags\n",
    "  WHERE key = 'amenity'\n",
    "  GROUP BY value\n",
    "  ORDER BY num DESC\n",
    "  LIMIT 10;\n",
    "```\n",
    "```\n",
    "school           608\n",
    "place_of_worship 508\n",
    "grave_yard       410\n",
    "restaurant       177\n",
    "library          116\n",
    "fire_station     112\n",
    "parking           88\n",
    "fast_food         77\n",
    "bench             72\n",
    "kindergarten      63\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fun, I decided to query the most common fast food resaurants in RI.\n",
    "```SQL\n",
    "SELECT nodes_tags.value, count(*) as num\n",
    "  FROM nodes_tags\n",
    "  JOIN (SELECT DISTINCT(id) \n",
    "        FROM nodes_tags \n",
    "        WHERE value = 'fast_food') as ff\n",
    "        ON nodes_tags.id = ff.id\n",
    "  WHERE nodes_tags.key = 'name'\n",
    "  GROUP BY nodes_tags.value\n",
    "  ORDER BY num DESC\n",
    "  LIMIT 4;\n",
    "```\n",
    "```\n",
    "Subway         13\n",
    "Dunkin' Donuts  9\n",
    "McDonald's      4\n",
    "Burger King     3\n",
    "```\n",
    "I'm very surprised that Dunkin is not the top. I think most other Rhode Islanders would be too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I looked into the nature tags, and their frequency.\n",
    "```SQL\n",
    "SELECT value, count(*) as num\n",
    "  FROM nodes_tags\n",
    "  WHERE key = 'natural'\n",
    "  GROUP BY value\n",
    "  ORDER BY num DESC;\n",
    "```\n",
    "```\n",
    "tree   1249\n",
    "peak    236\n",
    "bay     128\n",
    "beach    73\n",
    "wetland  51\n",
    "cliff    10\n",
    "wood      3\n",
    "cape      1\n",
    "rock      1\n",
    "```\n",
    "Trees are by far the most common nature tags. I'm surpriesed to see a rock, let's look into what that is!\n",
    "\n",
    "```SQL\n",
    "SELECT nodes_tags.value\n",
    "  FROM nodes_tags\n",
    "  JOIN (SELECT DISTINCT(id)\n",
    "        FROM nodes_tags\n",
    "        WHERE value = 'rock') as rock\n",
    "        ON nodes_tags.id = rock.id\n",
    "  WHERE nodes_tags.key = 'name';\n",
    "```\n",
    "This query returns __Elbow Rock__.\n",
    "\n",
    "I'm not totally sure what Elbow Rock is, but a quick search seems to show that there is hiking trail near it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions, Ideas, and Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach for analyzing OpenStreetMap data works well overall, allowing easy creation of the csv files and database. One possible improvement would be to split the users into a separate table with the primary key uid and the user values. It would make it easier to identify distinct users, and you could easily store more information about each user in that table. For example, you could use it to distinguish between bot and human users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT user, count(*) AS num\n",
    "FROM nodes\n",
    "GROUP BY uid\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;\n",
    "```\n",
    "```\n",
    "woodpeck_fixbot 338103\n",
    "greggerm        212390\n",
    "Zirnch           26848\n",
    "maxerickson      17340\n",
    "John Wrenn       16771\n",
    "ZeLonewolf       16466\n",
    "morganwahl        9693\n",
    "Roman Guy         9432\n",
    "GeoStudent        9419\n",
    "TIGERcnl          8440\n",
    "```\n",
    "Looking at the top ten users in nodes, it is clear that some bots are an order of magnitude higher in contribution than some other users. I think it would be very useful to have a table with more information about each user or bot and the kind of data they upload. It might be useful to identify some biases in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other issued that I had occured during csv import to SQL. I got a 'datatype mismatch' error on the first line for the nodes and ways tables only. I'm not sure what in the header causes this error.\n",
    "\n",
    "The error:\n",
    "nodes.csv:1: INSERT failed: datatype mismatch"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
